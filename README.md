# ğŸ” STREAM â€” Suspicious Transaction Risk Engine for Anomaly Monitoring

> **Anti-Corruption Procurement Fraud Detection Engine**
> AIA-26 Hackathon â€” Anna University

STREAM is a two-stage ML pipeline that detects suspicious procurement transactions in government tender data. It combines **rule-based red flag detection** with a **supervised machine learning model** to identify potentially corrupt or fraudulent contracts.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     python ml_model.py                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     â”‚                                           â”‚
â”‚   STAGE 1           â”‚   STAGE 2                                 â”‚
â”‚   Rule-Based        â”‚   Supervised ML                           â”‚
â”‚   Risk Scoring      â”‚   Classification                         â”‚
â”‚   (ml_model.py)     â”‚   (ml_pipeline.py)                       â”‚
â”‚                     â”‚                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Load all     â”‚   â”‚   â”‚ Create binary â”‚   â”‚ Train Gradient â”‚  â”‚
â”‚   â”‚ datasets/    â”‚   â”‚   â”‚ labels from  â”‚   â”‚ Boosting +     â”‚  â”‚
â”‚   â”‚ CSV files    â”‚   â”‚   â”‚ risk scores  â”‚   â”‚ Random Forest  â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚          â”‚                    â”‚           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Feature     â”‚   â”‚   â”‚ Feature      â”‚   â”‚ Pick best      â”‚  â”‚
â”‚   â”‚ Engineering â”‚   â”‚   â”‚ Engineering  â”‚   â”‚ model by       â”‚  â”‚
â”‚   â”‚ + Rule Flagsâ”‚   â”‚   â”‚ (all data)   â”‚   â”‚ ROC-AUC        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚          â”‚          â”‚                    â”‚           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Isolation   â”‚   â”‚   â”‚ Train/Test   â”‚   â”‚ Batch predict  â”‚  â”‚
â”‚   â”‚ Forest      â”‚   â”‚   â”‚ Split +      â”‚   â”‚ ALL datasets   â”‚  â”‚
â”‚   â”‚ Anomaly Det.â”‚   â”‚   â”‚ SMOTE        â”‚   â”‚ â†’ output_      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   datasets/    â”‚  â”‚
â”‚          â”‚          â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚                                          â”‚
â”‚   â”‚ Composite   â”‚   â”‚                                          â”‚
â”‚   â”‚ Risk Score  â”‚   â”‚                                          â”‚
â”‚   â”‚ (0-100)     â”‚   â”‚                                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                          â”‚
â”‚                     â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
STREAM/
â”œâ”€â”€ datasets/                    â† Drop your procurement CSVs here
â”‚   â”œâ”€â”€ ocds_..._2016_2017.csv
â”‚   â”œâ”€â”€ ocds_..._2017_2018.csv
â”‚   â”œâ”€â”€ ocds_..._2018_2019.csv
â”‚   â”œâ”€â”€ ocds_..._2019_2020.csv
â”‚   â””â”€â”€ ocds_..._2020_2021.csv
â”‚
â”œâ”€â”€ output_datasets/             â† All generated outputs
â”‚   â”œâ”€â”€ *_risk_scores.csv        â† Rule-based risk scores per dataset
â”‚   â”œâ”€â”€ *_predictions.csv        â† ML predictions per dataset
â”‚   â””â”€â”€ procurement_risk_scores.csv  â† Combined risk scores (ML training labels)
â”‚
â”œâ”€â”€ trained_model/               â† Saved ML model artifacts
â”‚   â”œâ”€â”€ model.joblib             â† Trained classifier
â”‚   â”œâ”€â”€ scaler.joblib            â† Feature scaler
â”‚   â”œâ”€â”€ label_encoders.joblib    â† Categorical encoders
â”‚   â”œâ”€â”€ feature_cols.joblib      â† Feature column list
â”‚   â””â”€â”€ training_report.json     â† Metrics summary
â”‚
â”œâ”€â”€ ml_model.py                  â† ğŸš€ Main entry point (run this)
â”œâ”€â”€ ml_pipeline.py               â† Supervised ML training + prediction
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install pandas numpy scikit-learn joblib
```

Optional (for better class balancing):

```bash
pip install imbalanced-learn
```

### 2. Add Your Data

Place procurement CSV files in the `datasets/` folder. They should follow the [OCDS (Open Contracting Data Standard)](https://www.open-contracting.org/data-standard/) schema with these required columns:

| Column                               | Description                |
| ------------------------------------ | -------------------------- |
| `ocid`                               | Open Contracting ID        |
| `tender/id`                          | Tender identifier          |
| `tender/title`                       | Tender title               |
| `buyer/name`                         | Procuring entity           |
| `tender/value/amount`                | Contract value             |
| `tender/numberOfTenderers`           | Number of bidders          |
| `tender/tenderPeriod/durationInDays` | Tender window              |
| `tender/procurementMethod`           | Open Tender / Limited etc. |
| `tenderclassification/description`   | Category                   |
| `tender/bidOpening/date`             | Bid opening date           |
| `tender/datePublished`               | Publication date           |

### 3. Run the Full Pipeline

```bash
python ml_model.py
```

This single command does everything:

1. **Rule-scores** every CSV in `datasets/`
2. **Trains** the ML model on the combined labeled data
3. **Predicts** on all datasets
4. **Saves** everything to `output_datasets/`

---

## ğŸ”¬ How It Works

### Stage 1: Rule-Based Risk Scoring (`ml_model.py`)

Seven expert-defined red flags are computed for each tender, each with a weight reflecting its severity:

| Flag                   | Weight | What It Detects                                          |
| ---------------------- | ------ | -------------------------------------------------------- |
| ğŸ”´ Single Bidder       | 25     | Only 1 bidder â€” possible bid-rigging                     |
| ğŸ”´ Zero Bidders        | 20     | No bidders recorded â€” possibly pre-awarded               |
| ğŸŸ¡ Short Window        | 15     | Tender period < 7 days â€” rushed, limits competition      |
| ğŸŸ¡ Non-Open Method     | 10     | Limited/restricted procurement â€” less transparency       |
| ğŸŸ¡ High Value          | 10     | Amount > 95th percentile for category â€” inflated pricing |
| ğŸŸ¡ Buyer Concentration | 10     | Buyer handles > 70% of category â€” monopoly risk          |
| ğŸŸ¢ Round Amount        | 5      | Contract divisible by â‚¹100,000 â€” possible fixed pricing  |
| ğŸ¤– ML Anomaly          | 15     | Isolation Forest statistical outlier                     |

These flags produce a **composite risk score (0â€“100)** and a **risk tier**:

- ğŸŸ¢ **Low** (0â€“30): No major flags
- ğŸŸ¡ **Medium** (30â€“60): Multiple flags triggered
- ğŸ”´ **High** (60â€“100): Strong indicators of corruption

### Stage 2: Supervised ML Classification (`ml_pipeline.py`)

The rule-based risk scores are used as **training labels** (`is_suspicious = 1` if `risk_score â‰¥ 20`) to train a supervised classifier:

1. **Feature Engineering** â€” 9 features: amount, log amount, tenderer count, duration, round amount flag, buyer-relative amount, procurement method, category, buyer (encoded)
2. **Class Balancing** â€” SMOTE oversampling (or `class_weight='balanced'` fallback)
3. **Two Models Trained** â€” GradientBoosting and RandomForest
4. **Best Model Selected** â€” By ROC-AUC score
5. **Batch Prediction** â€” All datasets scored with `predicted_suspicious` (0/1) and `suspicion_probability`

### Why Two Stages?

|            | Rule-Based (Stage 1)                  | ML Model (Stage 2)                                 |
| ---------- | ------------------------------------- | -------------------------------------------------- |
| **Pros**   | Interpretable, domain-expert designed | Generalizes to new data, captures complex patterns |
| **Cons**   | Fixed rules, can't learn new patterns | Needs labeled data to train                        |
| **Output** | `risk_score` (0â€“100) + explanations   | `predicted_suspicious` (0/1) + probability         |

The ML model learns from the rule-based labels, then can **score new procurement data instantly** without re-running the full rule engine.

---

## ğŸ“Š Model Performance (29,542 training records)

| Metric                     | Score  |
| -------------------------- | ------ |
| **ROC-AUC**                | 0.9939 |
| **Accuracy**               | 97%    |
| **Precision (Suspicious)** | 95%    |
| **Recall (Suspicious)**    | 90%    |
| **F1 (Suspicious)**        | 93%    |

### Top Features by Importance

| Rank | Feature                | Importance |
| ---- | ---------------------- | ---------- |
| 1    | `num_tenderers`        | 46.2%      |
| 2    | `amount_vs_buyer_avg`  | 17.4%      |
| 3    | `duration_days`        | 9.9%       |
| 4    | `log_amount`           | 7.3%       |
| 5    | `tenderclassification` | 7.3%       |

---

## ğŸ“‹ Output Format

Each prediction CSV contains:

| Column                  | Description                       |
| ----------------------- | --------------------------------- |
| `ocid`                  | Contract ID                       |
| `tender/id`             | Tender ID                         |
| `tender/title`          | Description                       |
| `buyer/name`            | Procuring entity                  |
| `amount`                | Contract value                    |
| `num_tenderers`         | Number of bidders                 |
| `predicted_suspicious`  | **1** = suspicious, **0** = clean |
| `suspicion_probability` | Model confidence (0.0 â€“ 1.0)      |
| `predicted_risk_tier`   | ğŸŸ¢ Low / ğŸŸ¡ Medium / ğŸ”´ High      |

---

## ğŸ”„ Adding New Data

1. Drop new procurement CSV files into `datasets/`
2. Run `python ml_model.py`
3. Find predictions in `output_datasets/`

To score a single file without retraining:

```bash
python ml_pipeline.py predict path/to/new_data.csv output.csv
```

---

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- **pandas / numpy** â€” Data processing
- **scikit-learn** â€” ML models (GradientBoosting, RandomForest, IsolationForest)
- **imbalanced-learn** _(optional)_ â€” SMOTE oversampling
- **joblib** â€” Model persistence

---

## ğŸ“œ License

Built for the AIA-26 Hackathon at Anna University.
