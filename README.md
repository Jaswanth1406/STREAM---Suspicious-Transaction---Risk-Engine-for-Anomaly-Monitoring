# ğŸ” STREAM â€” Suspicious Transaction Risk Engine for Anomaly Monitoring

> **Anti-Corruption Procurement Fraud Detection Engine**  
> AIA-26 Hackathon â€” Anna University

STREAM is a two-stage ML pipeline that detects suspicious procurement transactions in government tender data. It combines **rule-based red flag detection** with a **supervised machine learning model** to identify potentially corrupt or fraudulent contracts, served through a **FastAPI backend** and a **Next.js frontend** with Better Auth authentication.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          STREAM Pipeline                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”‚                                               â”‚
â”‚   STAGE 1            â”‚   STAGE 2                                     â”‚
â”‚   Rule-Based         â”‚   Supervised ML                               â”‚
â”‚   Risk Scoring       â”‚   Classification                             â”‚
â”‚   (ml_model.py)      â”‚   (ml_pipeline.py)                           â”‚
â”‚                      â”‚                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Load all     â”‚   â”‚   â”‚ Create binary â”‚   â”‚ Train Gradient  â”‚    â”‚
â”‚   â”‚ datasets/    â”‚   â”‚   â”‚ labels from  â”‚   â”‚ Boosting +      â”‚    â”‚
â”‚   â”‚ CSV files    â”‚   â”‚   â”‚ risk scores  â”‚   â”‚ Random Forest   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚          â”‚           â”‚          â”‚                     â”‚             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Feature      â”‚   â”‚   â”‚ Feature      â”‚   â”‚ Pick best       â”‚    â”‚
â”‚   â”‚ Engineering  â”‚   â”‚   â”‚ Engineering  â”‚   â”‚ model by        â”‚    â”‚
â”‚   â”‚ + Rule Flags â”‚   â”‚   â”‚ (all data)   â”‚   â”‚ ROC-AUC         â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚          â”‚           â”‚          â”‚                     â”‚             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Isolation    â”‚   â”‚   â”‚ Train/Test   â”‚   â”‚ Batch predict   â”‚    â”‚
â”‚   â”‚ Forest       â”‚   â”‚   â”‚ Split +      â”‚   â”‚ ALL datasets    â”‚    â”‚
â”‚   â”‚ Anomaly Det. â”‚   â”‚   â”‚ SMOTE        â”‚   â”‚ â†’ output_       â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   datasets/     â”‚    â”‚
â”‚          â”‚           â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚                                             â”‚
â”‚   â”‚ Composite    â”‚   â”‚                                             â”‚
â”‚   â”‚ Risk Score   â”‚   â”‚                                             â”‚
â”‚   â”‚ (0-100)      â”‚   â”‚                                             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                             â”‚
â”‚                      â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI REST   â”‚          â”‚   Next.js        â”‚
â”‚   API (app.py)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Frontend       â”‚
â”‚   Port 8000      â”‚          â”‚   Port 3000      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚  Better Auth     â”‚
                              â”‚  (Google + Email) â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
STREAM/
â”œâ”€â”€ backend/                           â† Python ML + API Server
â”‚   â”œâ”€â”€ datasets/                      â† Drop procurement CSVs here
â”‚   â”‚   â”œâ”€â”€ ocds_..._2016_2017.csv
â”‚   â”‚   â”œâ”€â”€ ocds_..._2017_2018.csv
â”‚   â”‚   â”œâ”€â”€ ocds_..._2018_2019.csv
â”‚   â”‚   â”œâ”€â”€ ocds_..._2019_2020.csv
â”‚   â”‚   â””â”€â”€ ocds_..._2020_2021.csv
â”‚   â”œâ”€â”€ output_datasets/               â† Generated outputs
â”‚   â”‚   â”œâ”€â”€ *_risk_scores.csv
â”‚   â”‚   â”œâ”€â”€ *_predictions.csv
â”‚   â”‚   â””â”€â”€ procurement_risk_scores.csv
â”‚   â”œâ”€â”€ trained_model/                 â† Saved ML model artifacts
â”‚   â”‚   â”œâ”€â”€ model.joblib
â”‚   â”‚   â”œâ”€â”€ scaler.joblib
â”‚   â”‚   â”œâ”€â”€ label_encoders.joblib
â”‚   â”‚   â”œâ”€â”€ feature_cols.joblib
â”‚   â”‚   â””â”€â”€ training_report.json
â”‚   â”œâ”€â”€ ml_model.py                    â† ğŸš€ Main ML entry point
â”‚   â”œâ”€â”€ ml_pipeline.py                 â† ML training + prediction
â”‚   â”œâ”€â”€ app.py                         â† FastAPI REST API
â”‚   â”œâ”€â”€ create_auth_tables.py          â† DB migration script
â”‚   â””â”€â”€ .env                           â† Backend secrets
â”‚
â”œâ”€â”€ frontend/                          â† Next.js + Better Auth
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/auth/[...all]/route.ts â† Auth API handler
â”‚   â”‚   â”œâ”€â”€ sign-in/page.tsx           â† Sign in page
â”‚   â”‚   â”œâ”€â”€ sign-up/page.tsx           â† Sign up page
â”‚   â”‚   â””â”€â”€ dashboard/page.tsx         â† Protected dashboard
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ auth.ts                    â† Better Auth server config
â”‚   â”‚   â””â”€â”€ auth-client.ts             â† Better Auth React client
â”‚   â””â”€â”€ .env.local                     â† Frontend secrets
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** with pip
- **Node.js 18+** with npm
- **Neon PostgreSQL** database (or any PostgreSQL)

### 1. Clone & Setup Backend

```bash
cd backend

# Install Python dependencies
pip install pandas numpy scikit-learn joblib fastapi uvicorn python-multipart psycopg2-binary python-dotenv imbalanced-learn

# Configure environment
cp .env.example .env   # Then fill in your DATABASE_URL

# Create auth tables in Neon
python create_auth_tables.py

# Train model + score all datasets
python ml_model.py

# Start API server
uvicorn app:app --reload
# â†’ http://localhost:8000/docs
```

### 2. Setup Frontend

```bash
cd frontend

# Install dependencies
npm install

# Configure environment
cp .env.local.example .env.local   # Then fill in your secrets

# Start dev server
npm run dev
# â†’ http://localhost:3000
```

### 3. Environment Variables

**`backend/.env`**

```env
DATABASE_URL=postgresql://user:pass@host/dbname?sslmode=require
```

**`frontend/.env.local`**

```env
DATABASE_URL=postgresql://user:pass@host/dbname?sslmode=require
BETTER_AUTH_SECRET=your-32-char-secret
BETTER_AUTH_URL=http://localhost:3000
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸ” Authentication

STREAM uses [Better Auth](https://better-auth.com) with:

| Method             | Description                     |
| ------------------ | ------------------------------- |
| **Email/Password** | Traditional sign-up and sign-in |
| **Google OAuth**   | One-click sign-in via Google    |

**Database tables:** `user`, `session`, `account`, `verification` â€” all stored in Neon PostgreSQL.

**Google OAuth Setup:**

1. Go to [Google Cloud Console â†’ Credentials](https://console.cloud.google.com/apis/credentials)
2. Create an OAuth 2.0 Client ID
3. Set **Authorized JavaScript origins:** `http://localhost:3000`
4. Set **Authorized redirect URIs:** `http://localhost:3000/api/auth/callback/google`
5. Copy Client ID and Secret to `frontend/.env.local`

---

## ğŸŒ API Endpoints

| Method | Endpoint              | Description                                 |
| ------ | --------------------- | ------------------------------------------- |
| `GET`  | `/`                   | Health check                                |
| `GET`  | `/model/info`         | Model metrics (ROC-AUC, accuracy, features) |
| `POST` | `/predict`            | Score a single tender (JSON body)           |
| `POST` | `/predict/batch`      | Upload CSV â†’ download predictions CSV       |
| `POST` | `/predict/batch/json` | Upload CSV â†’ get JSON summary               |

**Example â€” score a single tender:**

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "tender/value/amount": 5000000,
    "tender/numberOfTenderers": 1,
    "tender/tenderPeriod/durationInDays": 3,
    "tender/procurementMethod": "Limited",
    "tenderclassification/description": "Civil Works",
    "buyer/name": "Public Works Department"
  }'
```

---

## ğŸ”¬ How It Works

### Stage 1: Rule-Based Risk Scoring (`ml_model.py`)

Seven expert-defined red flags are computed for each tender:

| Flag                   | Weight | What It Detects                                          |
| ---------------------- | ------ | -------------------------------------------------------- |
| ğŸ”´ Single Bidder       | 25     | Only 1 bidder â€” possible bid-rigging                     |
| ğŸ”´ Zero Bidders        | 20     | No bidders recorded â€” possibly pre-awarded               |
| ğŸŸ¡ Short Window        | 15     | Tender period < 7 days â€” rushed, limits competition      |
| ğŸŸ¡ Non-Open Method     | 10     | Limited/restricted procurement â€” less transparency       |
| ğŸŸ¡ High Value          | 10     | Amount > 95th percentile for category â€” inflated pricing |
| ğŸŸ¡ Buyer Concentration | 10     | Buyer handles > 70% of category â€” monopoly risk          |
| ğŸŸ¢ Round Amount        | 5      | Divisible by â‚¹100,000 â€” possible fixed pricing           |
| ğŸ¤– ML Anomaly          | 15     | Isolation Forest statistical outlier                     |

**Risk Tiers:** ğŸŸ¢ Low (0â€“30) Â· ğŸŸ¡ Medium (30â€“60) Â· ğŸ”´ High (60â€“100)

### Stage 2: Supervised ML Classification (`ml_pipeline.py`)

Rule-based scores become **training labels** (`is_suspicious = 1` if `risk_score â‰¥ 20`):

1. **Feature Engineering** â€” 9 features from raw data
2. **Class Balancing** â€” SMOTE oversampling
3. **Two Models Trained** â€” GradientBoosting + RandomForest
4. **Best Model Selected** â€” By ROC-AUC score
5. **Batch Prediction** â€” All datasets scored and saved

### Why Two Stages?

|            | Rule-Based (Stage 1)                  | ML Model (Stage 2)                         |
| ---------- | ------------------------------------- | ------------------------------------------ |
| **Pros**   | Interpretable, domain-expert designed | Generalizes, captures complex patterns     |
| **Cons**   | Fixed rules, can't learn              | Needs labeled data to train                |
| **Output** | `risk_score` (0â€“100) + explanations   | `predicted_suspicious` (0/1) + probability |

---

## ğŸ“Š Model Performance (29,542 records)

| Metric                     | Score  |
| -------------------------- | ------ |
| **ROC-AUC**                | 0.9939 |
| **Accuracy**               | 97%    |
| **Precision (Suspicious)** | 95%    |
| **Recall (Suspicious)**    | 90%    |
| **F1 (Suspicious)**        | 93%    |

**Top Features:** `num_tenderers` (46.2%) Â· `amount_vs_buyer_avg` (17.4%) Â· `duration_days` (9.9%) Â· `log_amount` (7.3%)

---

## ğŸ“‹ Output Format

Each prediction CSV in `output_datasets/` contains:

| Column                  | Description                       |
| ----------------------- | --------------------------------- |
| `ocid`                  | Contract ID                       |
| `tender/id`             | Tender ID                         |
| `tender/title`          | Description                       |
| `buyer/name`            | Procuring entity                  |
| `amount`                | Contract value                    |
| `num_tenderers`         | Number of bidders                 |
| `predicted_suspicious`  | **1** = suspicious, **0** = clean |
| `suspicion_probability` | Model confidence (0.0â€“1.0)        |
| `predicted_risk_tier`   | ğŸŸ¢ Low / ğŸŸ¡ Medium / ğŸ”´ High      |

---

## ğŸ”„ Adding New Data

1. Drop new OCDS-format CSV files into `backend/datasets/`
2. Run `python ml_model.py` from `backend/`
3. Find predictions in `backend/output_datasets/`

---

## ğŸ› ï¸ Tech Stack

| Layer              | Technologies                                                     |
| ------------------ | ---------------------------------------------------------------- |
| **ML Pipeline**    | Python, pandas, scikit-learn, Isolation Forest, GradientBoosting |
| **Backend API**    | FastAPI, Uvicorn                                                 |
| **Frontend**       | Next.js 15, TypeScript, Tailwind CSS                             |
| **Authentication** | Better Auth (Email/Password + Google OAuth)                      |
| **Database**       | Neon PostgreSQL                                                  |

---

## ğŸ“œ License

Built for the AIA-26 Hackathon at Anna University.
